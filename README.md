# Object-Centric Reinforcement Learning for NPCs: A Comprehensive Analysis

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![Paper](https://img.shields.io/badge/Paper-Thesis-green.svg)](thesis%20docs/masters_thesis.pdf)

This research project investigates the boundaries between reinforcement learning and transformer-based reasoning systems for spatial intelligence tasks. The study demonstrates that **SLM-based program synthesis achieves 100% success with perfect generalization** while traditional RL methods fail to generalize beyond the KeyDoor training distribution (0% success on novel environments).

## üéØ Core Research Question

**Can traditional RL methods match the spatial reasoning and generalization capabilities of transformer-based program synthesis approaches?**

Our findings prove that transformer architectures with natural language reasoning fundamentally outperform neural RL approaches in spatial reasoning domains.

## üìä Key Results

| Method | Training Success | Novel Success | Generalization Gap |
|--------|------------------|---------------|-------------------|
| **SLM Program Synthesis** | **100%** | **100%** | **0%** |
| BC Raw/Abstract | 100% | 0% | 100% |
| MoE Raw/Abstract | 100% | 0% | 100% |
| PPO Raw/Abstract | 10-17% | 8-10% | ~85% |

## üèóÔ∏è Project Structure

```
Masters_project/
‚îú‚îÄ‚îÄ agents/                          # RL Agent Implementations
‚îÇ   ‚îú‚îÄ‚îÄ bc/                         # Behavioral Cloning agents
‚îÇ   ‚îú‚îÄ‚îÄ moe/                        # Mixture of Experts agents
‚îÇ   ‚îî‚îÄ‚îÄ ppo/                        # PPO agents
‚îú‚îÄ‚îÄ datasets/                        # Training datasets and generation
‚îú‚îÄ‚îÄ dungeon_game/                    # Memory Maze: Exploratory 80√ó20 benchmarking pygame for future AI agents‚Äî80√ó20
‚îú‚îÄ‚îÄ envs/                           # KeyDoor environment implementations
‚îú‚îÄ‚îÄ experiments/                     # Trained model checkpoints and results
‚îú‚îÄ‚îÄ results/                        # Thesis visualizations and analysis
‚îÇ   ‚îú‚îÄ‚îÄ figures/                    # Generated charts and graphs
‚îÇ   ‚îî‚îÄ‚îÄ data/                       # Experimental results data
‚îú‚îÄ‚îÄ scripts/                        # Training and testing scripts
‚îÇ   ‚îú‚îÄ‚îÄ bc/                         # BC training/testing scripts
‚îÇ   ‚îú‚îÄ‚îÄ moe/                        # MoE training/testing scripts
‚îÇ   ‚îî‚îÄ‚îÄ ppo/                        # PPO training/testing scripts
‚îú‚îÄ‚îÄ slm-program-synthesis_keydoor/   # SLM Implementation
‚îú‚îÄ‚îÄ sprites/                        # Game sprites and visual assets
‚îú‚îÄ‚îÄ templates/                      # Environment template definitions
```

## üöÄ Quick Start

### Prerequisites

- **Python 3.8+**
- **Git**
- **Ollama** (for SLM approach)

### 1. Clone Repository

```bash
git clone https://github.com/yourusername/object-centric-rl-npcs.git
cd object-centric-rl-npcs
```

### 2. Install Core Dependencies

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install core dependencies
pip install torch torchvision numpy pygame gymnasium matplotlib seaborn pandas scipy
```

### 3. Quick Demo - SLM Program Synthesis (Recommended)

The **breakthrough approach** that achieves perfect generalization:

```bash
# Install Ollama (if not already installed)
# Visit: https://ollama.ai/

# Pull Llama 3.2 3B model
ollama pull llama3.2:3b

# Install SLM dependencies
cd slm-program-synthesis_keydoor/
pip install -r requirements.txt

# Run SLM demo
python slm_demo.py
```

**Expected Output**: 100% success rate with step-by-step spatial reasoning

## üì¶ Installation Guide

### Option 1: SLM Program Synthesis Only (Recommended)

slm outperforms all RL methods:

```bash
cd slm-program-synthesis_keydoor/
pip install ollama>=0.1.0 numpy>=1.21.0 dataclasses-json>=0.5.0
ollama pull llama3.2:3b
python slm_demo.py
```

### Option 2: Complete Research Environment

For reproducing all experiments and comparisons:

```bash
# Install all dependencies
pip install -r requirements_full.txt

# Or install manually:
pip install torch>=1.9.0 torchvision numpy>=1.21.0 pygame>=2.0.0
pip install gymnasium matplotlib>=3.5.0 seaborn>=0.11.0 pandas scipy
pip install stable-baselines3 tensorboard

# For SLM approach
pip install ollama>=0.1.0 dataclasses-json>=0.5.0

# Install Ollama and pull model
ollama pull llama3.2:3b
```

## üéÆ Running Experiments

### SLM Program Synthesis (Perfect Performance)

```bash
cd slm-program-synthesis_keydoor/

# Quick demo
python slm_demo.py

# Full environment test
python test_slm_env.py  

# Visual pygame test
python test_slm_pygame.py
```

### Traditional RL Methods

#### Behavioral Cloning
```bash
cd scripts/bc/

# Train BC models
python train_bc_abstract.py
python train_bc_raw.py

# Test BC models  
python test_bc_abstract.py
python test_bc_raw.py
```

#### Mixture of Experts
```bash
cd scripts/moe/

# Train MoE models
python train_moe_abstract.py
python train_moe_raw.py

# Test MoE models
python test_moe_abstract.py
python test_moe_raw.py
```

#### PPO (Policy Gradient)
```bash
cd scripts/ppo/

# Train PPO models
python train_ppo_abstract.py
python train_ppo_raw.py

# Test PPO models
python test_ppo_abstract.py
python test_ppo_raw.py
```

## üî¨ Key Research Findings

### 1. **SLM Program Synthesis Breakthrough**
- **100% success rate** on both training and novel environments
- **Perfect generalization** with 0% generalization gap
- **Natural language reasoning** enables spatial intelligence
- **Ready-to-deploy** without training requirements

### 2. **Traditional RL Limitations**
- **Catastrophic generalization failure**: 0% success on novel environments
- **Object-centric representations provide no advantage** over raw pixels
- **Covariate shift** is the fundamental limiting factor
- **Perfect training performance** followed by complete failure

### 3. **Paradigm Shift Evidence**
- **Statistical learning (RL) vs. Symbolic reasoning (Transformers)**
- **Pre-trained world knowledge** beats learned patterns
- **Compositional understanding** enables true generalization
- **Natural language integration** provides spatial reasoning capabilities

### 4. **Memory Maze Exploratory Insights**
- **AI Evaluation Testbed**: An 80√ó20 grid-based dungeon crawler designed as a benchmark for assessing next-gen AI game agents' spatial intelligence, memory, and multi-modal capabilities‚Äîe.g., invisible mazes test long-term planning, password systems evaluate coordinate/math integration.
- **Thesis Insights for Future Work**: Documents baseline limitations (e.g., 35-80% VLM accuracy in coordinate recognition and command generation) to guide hybrid AI development; ideal for benchmarking RL, VLM, and SLM agents in complex, dynamic environments
- **Implementation Note**: Built as an 80√ó20 grid-based dungeon maze `dungeon_game/` - its a benchmarking game for future ai game agents to prototype and measure progress toward human-level game AI.

## üìÅ Dataset Information

The research uses the **KeyDoor Environment** with:
- **10 templates** (T1-T6 training, T7-T10 novel)
- **Grid-based navigation** (6√ó6 to 12√ó12)
- **Spatial reasoning tasks**: collect keys, open doors
- **Perfect expert demonstrations** from oracle policy
- **5,100+ training observations**

## üèÜ Performance Benchmarks

### SLM Program Synthesis Performance
| Template | Type | Success | Steps | Response Time |
|----------|------|---------|-------|---------------|
| T1-T6 | Training | 100% | 16.5 avg | 3.4s avg |
| T7-T10 | Novel | 100% | 16.5 avg | 3.4s avg |

### Traditional RL Comparison
- **BC Methods**: 100% training ‚Üí 0% novel
- **MoE Methods**: 100% training ‚Üí 0% novel  
- **PPO Methods**: 10-17% training ‚Üí 8-10% novel

## üõ†Ô∏è Troubleshooting

### Common Issues

**1. Ollama Connection Error**
```bash
# Ensure Ollama is running
ollama serve

# Check if model is available
ollama list
```

**2. Missing Dependencies**
```bash
# Install missing packages
pip install torch numpy pygame gymnasium matplotlib seaborn
```

**3. CUDA Issues (Optional)**
```bash
# For GPU support (optional)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

**4. Permission Issues**
```bash
# If file permission errors occur
chmod +x scripts/*.py
```

## üéØ Usage Examples

### 1. Run SLM Demo
```python
from keydoor_slm_env import KeyDoorSLMEnv
from slm_agent import SLMKeyDoorAgent

env = KeyDoorSLMEnv(grid_size=8)
agent = SLMKeyDoorAgent(model_name="llama3.2:3b")

obs, info = env.reset(template_id=1)
action = agent.act(env)  # Returns optimal action with reasoning
```

### 2. Train RL Agent
```python
from agents.bc.bc_abstract import BCAbstract
from envs.keydoor.keydoor_env import KeyDoorEnv

env = KeyDoorEnv()
agent = BCAbstract()
# Training code...
```

### 3. Generate Visualizations
```python
from results.generate_thesis_visualizations import ThesisVisualizationGenerator

generator = ThesisVisualizationGenerator()
generator.generate_all_visualizations()
```

## üìà Research Impact

This research demonstrates:

1. **Paradigm Boundaries**: Clear evidence of transformer superiority over RL
2. **Practical Applications**: Ready-to-deploy spatial reasoning without training
3. **Theoretical Insights**: Statistical learning vs. symbolic reasoning limitations
4. **Future Directions**: Hybrid approaches combining RL efficiency with transformer reasoning
5. **Benchmarking Framework**: Memory Maze delivers a custom-engineered puzzle game testbed for next-gen AI agents, offering  to evaluate spatial and multi-modal reasoning capabilities.

## üë• Authors

- **Sharath Bandari** 

## üôè Acknowledgments

- Ollama team for the excellent LLM serving framework
- Llama 3.2 3B model for spatial reasoning capabilities
- Research community for foundational work in object-centric learning
- Open source contributors for the tools and libraries used

---

**üéì Master's Thesis Research Project**  
**Bournemouth University | Year 2025**  
**Supervisor: Jon Macey**
